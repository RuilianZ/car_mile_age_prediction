---
title: "Homework 3 for Data Science II"
author: "Roxy Zhang"
date: "3/22/2022"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(caret) # Classification And REgression Training
library(glmnet) # GLM models
library(MASS) # LDA QDA
library(pROC) # ROC curves
library(vip) # variable importance
library(klaR) # visualization
library(pdp) # partial dependence plot
library(AppliedPredictiveModeling) # transparent theme
library(reshape2) # melt() EDA visualization
library(ggcorrplot) # correlation plot

# set theme
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```


## Data import and cleaning

```{r}
auto = read_csv("auto.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    mpg_cat = as.factor(mpg_cat),
    mpg_cat = fct_relevel(mpg_cat, "low"),
    cylinders = as.factor(cylinders),
    year = as.factor(year),
    origin = case_when(
      origin == "1" ~ "American",
      origin == "2" ~ "European",
      origin == "3" ~ "Japanese"),
    origin = as.factor(origin)
    )

# reorder columns for future visualization
col_order = c("cylinders", "year", "origin",
               "displacement", "horsepower", "weight", "acceleration", "mpg_cat")
auto = auto[ , col_order]

# check for NA
colSums(is.na(auto))
```


## Data partition

Split the dataset into two parts: training data (70%) and test data (30%).

```{r}
set.seed(2570)

index_train = createDataPartition(
  y = auto$mpg_cat,
  p = 0.7,
  list = FALSE
)

train = auto[index_train, ]
test = auto[-index_train, ]

head(train)


# matrix of predictors
# x = model.matrix(mpg_cat~., auto)[ , -1] # remove intercept
# y = test$mpg_cat
```


## Exploratory Data Analysis

Produce some graphical or numerical summaries of the data.  

```{r}
dim(auto)

summary(auto)

skimr::skim(auto)
```

There are 392 rows and 8 columns in the full data, including 4 numeric predictors: `displacement`, `horsepower`, `weight`, `acceleration`, 3 categorical predictors: `cylinders`, `year`, `origin`, and 1 categorical response variable: `mpg_cat`.  

For better illustration, all EDA plots are done using train data.

```{r}
# visualization for numeric variables using feature plot

# set plot theme
theme1 = transparentTheme(trans = .4)
trellis.par.set(theme1)

# density plot
featurePlot(
  x = train %>% dplyr::select(displacement, horsepower, weight,  acceleration), 
  y = train$mpg_cat, 
  scales = list(x = list(relation = "free"),
                y = list(relation = "free")),
  plot = "density",
  pch = "|",
  auto.key = list(columns = 2))
```

The feature plot shows that higher MPG category is associated with lower weight,  higher acceleration, lower displacement and lower horsepower.

```{r}
# visualization for categorical variables using ggplot

train %>% 
  dplyr::select(-displacement, -horsepower, -weight, -acceleration) %>% 
  melt(id.vars = "mpg_cat") %>% 
  ggplot(aes(x = value, fill = mpg_cat)) + 
  geom_bar(position = "fill") + 
  #scale_y_continuous(labels = scales::percent) + # % on y axis
  labs(x = "",
       y = "Proportion",
       fill = "MPG Category", # legend title
       color = "MPG Category") +
  facet_wrap(~variable, scales = "free", nrow = 2)
```

This plot shows that higher MPG category mainly lies in cars with 5 or 6 cylinders, model year 1908s, and origin of European and Japanese.  

```{r}
# LAD partition plot for numeric variables
partimat(
  mpg_cat ~ displacement + horsepower + weight + acceleration,
  data = auto,
  subset = index_train,
  method = "lda")
```

The LDA partition plot is based on every combination of two numeric variables, which gives the decision boundrary of making classification.  
Red labels are misclassified data.  
Although in LDA we use all the predictors rather than just the combination of two predictors, this plot shows some potential patterns of the data (since we cannot visualize things easily in high-dimensional space).  

```{r}
# correlation plot for all data
model.matrix(mpg_cat~., data = train)[ , -1] %>% 
  cor(use = "pairwise.complete.obs") %>% 
  ggcorrplot(type = "full", lab = TRUE, lab_size = 1)
```

We can see from the correlation plot that the numeric predictors `displacement`, `horsepower`, `weight`, `acceleration` are highly correlated, which may potentially result in some redundancy for model building.  
Also, `cylinders8` is highly correlated with above numeric predictors.


## Logistic Regression

```{r}
set.seed(1115)

# check for the response variable level
contrasts(auto$mpg_cat)

# fit glm model
glm_fit = glm(
  mpg_cat ~ .,
  data = auto,
  subset = index_train,
  family = binomial(link = "logit"))

summary(glm_fit)
```

From the summary above, we can see that for the logistic regression model, `weight` and `originEuropean` are **statistically significant predictors** under 0.05 significance level, and `weight` is significant under 0.01 significance level.  

```{r}
# test model performance
test_pred_prob = predict(
  glm_fit,
  newdata = test,
  type = "response") # get predicted probabilities

test_pred = rep("low", length(test_pred_prob))

# use a simple classifier with a cut-off of 0.5
test_pred[test_pred_prob>0.5] = "high"

confusionMatrix(data = as.factor(test_pred),
                reference = test$mpg_cat,
                positive = "high")
```

* As the confusion matrix shows above, there are 52 true low MPG category and 50 true high MPG category, with a prediction accuracy of 0.8793.  
* The No Information Rate is 0.5, which means if we have no information at all and predict all the MPG category to be low (or high), the prediction accuracy will be 0.5.  
* The p-value is approximately 0, showing that the fitted model is significantly better than the one generates no information rate.  
* Sensitivity is 0.8621, which is the rate of predicting MPG category as high given the true value is high. Specificity is 0.8966, which is the rate of predicting MPG category as low given the true value is low.  
* Positive predictive value is 0.8929, which is the rate of a true high value given the predicted value is high. Negative predictive value is 0.8929, which is the rate of a true low value given the predicted value is low.  
* Kappa is 0.7586, which means the agreement of observations and predictions is relatively high.


## MARS (multivariate adaptive regression spline) model

```{r}
set.seed(1115)

ctrl = trainControl(
  method = "repeatedcv",
  summaryFunction = twoClassSummary,
  repeats = 5,
  classProbs = TRUE)

model.mars = train(
  x = auto[index_train, 1:7],
  y = auto$mpg_cat[index_train],
  method = "earth",
  tuneGrid = expand.grid(degree = 1:3,
                        nprune = 2:25),
  metric = "ROC",
  trControl = ctrl)

model_mars = train(
  x = train[ , 1:7],
  y = train$mpg_cat,
  method = "earth",
  tuneGrid = expand.grid(degree = 1:4,
                         nprune = 2:20),
  metric = "ROC",
  trControl = ctrl)

summary(model_mars)

plot(model_mars)

model_mars$bestTune

coef(model_mars$finalModel)

vip(model_mars$finalModel)
```

